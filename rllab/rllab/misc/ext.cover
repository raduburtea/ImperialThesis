    1: from pathlib import Path
    1: import sys
    1: import pickle as pickle
    1: import random
    1: from rllab.misc.console import colorize, Message
    1: from collections import OrderedDict
    1: import numpy as np
    1: import operator
    1: from functools import reduce
       
    1: sys.setrecursionlimit(50000)
       
       
    1: def extract(x, *keys):
    4:     if isinstance(x, (dict, lazydict)):
   18:         return tuple(x[k] for k in keys)
           elif isinstance(x, list):
               return tuple([xi[k] for xi in x] for k in keys)
           else:
               raise NotImplementedError
       
       
    1: def extract_dict(x, *keys):
           return {k: x[k] for k in keys if k in x}
       
       
    1: def flatten(xs):
           return [x for y in xs for x in y]
       
       
    1: def compact(x):
           """
           For a dictionary this removes all None values, and for a list this removes
           all None elements; otherwise it returns the input itself.
           """
           if isinstance(x, dict):
               return dict((k, v) for k, v in x.items() if v is not None)
           elif isinstance(x, list):
               return [elem for elem in x if elem is not None]
           return x
       
       
    1: def cached_function(inputs, outputs):
           import theano
           with Message("Hashing theano fn"):
               if hasattr(outputs, '__len__'):
                   hash_content = tuple(map(theano.pp, outputs))
               else:
                   hash_content = theano.pp(outputs)
           cache_key = hex(hash(hash_content) & (2 ** 64 - 1))[:-1]
           cache_dir = Path('~/.hierctrl_cache')
           cache_dir = cache_dir.expanduser()
           cache_dir.mkdir_p()
           cache_file = cache_dir / ('%s.pkl' % cache_key)
           if cache_file.exists():
               with Message("unpickling"):
                   with open(cache_file, "rb") as f:
                       try:
                           return pickle.load(f)
                       except Exception:
                           pass
           with Message("compiling"):
               fun = compile_function(inputs, outputs)
           with Message("picking"):
               with open(cache_file, "wb") as f:
                   pickle.dump(fun, f, protocol=pickle.HIGHEST_PROTOCOL)
           return fun
       
       
       # Immutable, lazily evaluated dict
    2: class lazydict(object):
    1:     def __init__(self, **kwargs):
    6:         self._lazy_dict = kwargs
    6:         self._dict = {}
       
    1:     def __getitem__(self, key):
  134:         if key not in self._dict:
   16:             self._dict[key] = self._lazy_dict[key]()
  134:         return self._dict[key]
       
    1:     def __setitem__(self, i, y):
               self.set(i, y)
       
    1:     def get(self, key, default=None):
               if key in self._lazy_dict:
                   return self[key]
               return default
       
    1:     def set(self, key, value):
               self._lazy_dict[key] = value
       
       
    1: def iscanl(f, l, base=None):
           started = False
           for x in l:
               if base or started:
                   base = f(base, x)
               else:
                   base = x
               started = True
               yield base
       
       
    1: def iscanr(f, l, base=None):
           started = False
           for x in list(l)[::-1]:
               if base or started:
                   base = f(x, base)
               else:
                   base = x
               started = True
               yield base
       
       
    1: def scanl(f, l, base=None):
           return list(iscanl(f, l, base))
       
       
    1: def scanr(f, l, base=None):
           return list(iscanr(f, l, base))
       
       
    1: def compile_function(inputs=None, outputs=None, updates=None, givens=None, log_name=None, **kwargs):
   23:     import theano
   23:     if log_name:
   17:         msg = Message("Compiling function %s" % log_name)
   17:         msg.__enter__()
   69:     ret = theano.function(
   23:         inputs=inputs,
   23:         outputs=outputs,
   23:         updates=updates,
   23:         givens=givens,
   23:         on_unused_input='ignore',
   23:         allow_input_downcast=True,
   23:         **kwargs
           )
   23:     if log_name:
   17:         msg.__exit__(None, None, None)
   23:     return ret
       
       
    1: def new_tensor(name, ndim, dtype):
   26:     import theano.tensor as TT
   26:     return TT.TensorType(dtype, (False,) * ndim)(name)
       
       
    1: def new_tensor_like(name, arr_like):
   19:     return new_tensor(name, arr_like.ndim, arr_like.dtype)
       
       
    2: class AttrDict(dict):
    1:     def __init__(self, *args, **kwargs):
               super(AttrDict, self).__init__(*args, **kwargs)
               self.__dict__ = self
       
       
    1: def is_iterable(obj):
           return isinstance(obj, str) or getattr(obj, '__iter__', False)
       
       
       # cut the path for any time >= t
    1: def truncate_path(p, t):
           return dict((k, p[k][:t]) for k in p)
       
       
    1: def concat_paths(p1, p2):
           import numpy as np
           return dict((k1, np.concatenate([p1[k1], p2[k1]])) for k1 in list(p1.keys()) if k1 in p2)
       
       
    1: def path_len(p):
           return len(p["states"])
       
       
    1: def shuffled(sequence):
           deck = list(sequence)
           while len(deck):
               i = random.randint(0, len(deck) - 1)  # choose random card
               card = deck[i]  # take the card
               deck[i] = deck[-1]  # put top card in its place
               deck.pop()  # remove top card
               yield card
       
       
    1: seed_ = None
       
       
    1: def set_seed(seed):
           seed %= 4294967294
           global seed_
           seed_ = seed
           import lasagne
           random.seed(seed)
           np.random.seed(seed)
           lasagne.random.set_rng(np.random.RandomState(seed))
           try:
               import tensorflow as tf
               tf.set_random_seed(seed)
           except Exception as e:
               print(e)
           print((
               colorize(
                   'using seed %s' % (str(seed)),
                   'green'
               )
           ))
       
       
    1: def get_seed():
           return seed_
       
       
    1: def flatten_hessian(cost, wrt, consider_constant=None,
                           disconnected_inputs='raise', block_diagonal=True):
           """
           :type cost: Scalar (0-dimensional) Variable.
           :type wrt: Vector (1-dimensional tensor) 'Variable' or list of
                      vectors (1-dimensional tensors) Variables
       
           :param consider_constant: a list of expressions not to backpropagate
               through
       
           :type disconnected_inputs: string
           :param disconnected_inputs: Defines the behaviour if some of the variables
               in ``wrt`` are not part of the computational graph computing ``cost``
               (or if all links are non-differentiable). The possible values are:
               - 'ignore': considers that the gradient on these parameters is zero.
               - 'warn': consider the gradient zero, and print a warning.
               - 'raise': raise an exception.
       
           :return: either a instance of Variable or list/tuple of Variables
                   (depending upon `wrt`) repressenting the Hessian of the `cost`
                   with respect to (elements of) `wrt`. If an element of `wrt` is not
                   differentiable with respect to the output, then a zero
                   variable is returned. The return value is of same type
                   as `wrt`: a list/tuple or TensorVariable in all cases.
           """
           import theano
           from theano.tensor import arange
           # Check inputs have the right format
           import theano.tensor as TT
           from theano import Variable
           from theano import grad
           assert isinstance(cost, Variable), \
               "tensor.hessian expects a Variable as `cost`"
           assert cost.ndim == 0, \
               "tensor.hessian expects a 0 dimensional variable as `cost`"
       
           using_list = isinstance(wrt, list)
           using_tuple = isinstance(wrt, tuple)
       
           if isinstance(wrt, (list, tuple)):
               wrt = list(wrt)
           else:
               wrt = [wrt]
       
           hessians = []
           if not block_diagonal:
               expr = TT.concatenate([
                                         grad(cost, input, consider_constant=consider_constant,
                                              disconnected_inputs=disconnected_inputs).flatten()
                                         for input in wrt
                                         ])
       
           for input in wrt:
               assert isinstance(input, Variable), \
                   "tensor.hessian expects a (list of) Variable as `wrt`"
               # assert input.ndim == 1, \
               #     "tensor.hessian expects a (list of) 1 dimensional variable " \
               #     "as `wrt`"
               if block_diagonal:
                   expr = grad(cost, input, consider_constant=consider_constant,
                               disconnected_inputs=disconnected_inputs).flatten()
       
               # It is possible that the inputs are disconnected from expr,
               # even if they are connected to cost.
               # This should not be an error.
               hess, updates = theano.scan(lambda i, y, x: grad(
                   y[i],
                   x,
                   consider_constant=consider_constant,
                   disconnected_inputs='ignore').flatten(),
                                           sequences=arange(expr.shape[0]),
                                           non_sequences=[expr, input])
               assert not updates, \
                   ("Scan has returned a list of updates. This should not "
                    "happen! Report this to theano-users (also include the "
                    "script that generated the error)")
               hessians.append(hess)
           if block_diagonal:
               from theano.gradient import format_as
               return format_as(using_list, using_tuple, hessians)
           else:
               return TT.concatenate(hessians, axis=1)
       
       
    1: def flatten_tensor_variables(ts):
    4:     import theano.tensor as TT
    4:     return TT.concatenate(list(map(TT.flatten, ts)))
       
       
    1: def flatten_shape_dim(shape):
           return reduce(operator.mul, shape, 1)
       
       
    1: def print_lasagne_layer(layer, prefix=""):
           params = ""
           if layer.name:
               params += ", name=" + layer.name
           if getattr(layer, 'nonlinearity', None):
               params += ", nonlinearity=" + layer.nonlinearity.__name__
           params = params[2:]
           print(prefix + layer.__class__.__name__ + "[" + params + "]")
           if hasattr(layer, 'input_layers') and layer.input_layers is not None:
               [print_lasagne_layer(x, prefix + "  ") for x in layer.input_layers]
           elif hasattr(layer, 'input_layer') and layer.input_layer is not None:
               print_lasagne_layer(layer.input_layer, prefix + "  ")
       
       
    1: def unflatten_tensor_variables(flatarr, shapes, symb_arrs):
           import theano.tensor as TT
           import numpy as np
           arrs = []
           n = 0
           for (shape, symb_arr) in zip(shapes, symb_arrs):
               size = np.prod(list(shape))
               arr = flatarr[n:n + size].reshape(shape)
               if arr.type.broadcastable != symb_arr.type.broadcastable:
                   arr = TT.patternbroadcast(arr, symb_arr.type.broadcastable)
               arrs.append(arr)
               n += size
           return arrs
       
       
       """
       Devide function f's inputs into several slices. Evaluate f on those slices, and then average the result. It is useful when memory is not enough to process all data at once.
       Assume:
       1. each of f's inputs is iterable and composed of multiple "samples"
       2. outputs can be averaged over "samples"
       """
    1: def sliced_fun(f, n_slices):
  134:     def sliced_f(sliced_inputs, non_sliced_inputs=None):
  134:         if non_sliced_inputs is None:
                   non_sliced_inputs = []
  134:         if isinstance(non_sliced_inputs, tuple):
  134:             non_sliced_inputs = list(non_sliced_inputs)
  134:         n_paths = len(sliced_inputs[0])
  134:         slice_size = max(1, n_paths // n_slices)
  134:         ret_vals = None
  268:         for start in range(0, n_paths, slice_size):
  990:             inputs_slice = [v[start:start + slice_size] for v in sliced_inputs]
  134:             slice_ret_vals = f(*(inputs_slice + non_sliced_inputs))
  134:             if not isinstance(slice_ret_vals, (tuple, list)):
  126:                 slice_ret_vals_as_list = [slice_ret_vals]
                   else:
    8:                 slice_ret_vals_as_list = slice_ret_vals
  548:             scaled_ret_vals = [
  280:                 np.asarray(v) * len(inputs_slice[0]) for v in slice_ret_vals_as_list]
  134:             if ret_vals is None:
  134:                 ret_vals = scaled_ret_vals
                   else:
                       ret_vals = [x + y for x, y in zip(ret_vals, scaled_ret_vals)]
  414:         ret_vals = [v / n_paths for v in ret_vals]
  134:         if not isinstance(slice_ret_vals, (tuple, list)):
  126:             ret_vals = ret_vals[0]
    8:         elif isinstance(slice_ret_vals, tuple):
                   ret_vals = tuple(ret_vals)
  134:         return ret_vals
       
  134:     return sliced_f
       
       
    1: def stdize(data, eps=1e-6):
           return (data - np.mean(data, axis=0)) / (np.std(data, axis=0) + eps)
       
       
    1: def iterate_minibatches_generic(input_lst=None, batchsize=None, shuffle=False):
    4:     if batchsize is None:
    4:         batchsize = len(input_lst[0])
       
   16:     assert all(len(x) == len(input_lst[0]) for x in input_lst)
       
    4:     if shuffle:
    4:         indices = np.arange(len(input_lst[0]))
    4:         np.random.shuffle(indices)
    8:     for start_idx in range(0, len(input_lst[0]), batchsize):
    4:         if shuffle:
    4:             excerpt = indices[start_idx:start_idx + batchsize]
               else:
                   excerpt = slice(start_idx, start_idx + batchsize)
   16:         yield [input[excerpt] for input in input_lst]
