    1: from rllab.misc import ext
    1: from rllab.misc import krylov
    1: from rllab.misc import logger
    1: from rllab.core.serializable import Serializable
    1: import theano.tensor as TT
    1: import theano
    1: import itertools
    1: import numpy as np
    1: from rllab.misc.ext import sliced_fun
       # from _ast import Num
       
       
    2: class PerlmutterHvp(Serializable):
       
    1:     def __init__(self, num_slices=1):
    1:         Serializable.quick_init(self, locals())
    1:         self.target = None
    1:         self.reg_coeff = None
    1:         self.opt_fun = None
    1:         self._num_slices = num_slices
       
    1:     def update_opt(self, f, target, inputs, reg_coeff):
    1:         self.target = target
    1:         self.reg_coeff = reg_coeff
    1:         params = target.get_params(trainable=True)
       
    2:         constraint_grads = theano.grad(
    1:             f, wrt=params, disconnected_inputs='warn')
    9:         xs = tuple([ext.new_tensor_like("%s x" % p.name, p) for p in params])
       
    1:         def Hx_plain():
    2:             Hx_plain_splits = TT.grad(
   17:                 TT.sum([TT.sum(g * x)
    8:                         for g, x in zip(constraint_grads, xs)]),
    1:                 wrt=params,
    1:                 disconnected_inputs='warn'
                   )
    9:             return TT.concatenate([TT.flatten(s) for s in Hx_plain_splits])
       
    2:         self.opt_fun = ext.lazydict(
    3:             f_Hx_plain=lambda: ext.compile_function(
    1:                 inputs=inputs + xs,
    1:                 outputs=Hx_plain(),
    1:                 log_name="f_Hx_plain",
                   ),
               )
       
    1:     def build_eval(self, inputs):
    2:         def eval(x):
   44:             xs = tuple(self.target.flat_to_params(x, trainable=True))
  132:             ret = sliced_fun(self.opt_fun["f_Hx_plain"], self._num_slices)(
   88:                 inputs, xs) + self.reg_coeff * x
   44:             return ret
       
    2:         return eval
       
       
    2: class FiniteDifferenceHvp(Serializable):
       
    1:     def __init__(self, base_eps=1e-8, symmetric=True, grad_clip=None, num_slices=1):
               Serializable.quick_init(self, locals())
               self.base_eps = base_eps
               self.symmetric = symmetric
               self.grad_clip = grad_clip
               self._num_slices = num_slices
       
    1:     def update_opt(self, f, target, inputs, reg_coeff):
               self.target = target
               self.reg_coeff = reg_coeff
       
               params = target.get_params(trainable=True)
       
               constraint_grads = theano.grad(
                   f, wrt=params, disconnected_inputs='warn')
               flat_grad = ext.flatten_tensor_variables(constraint_grads)
       
               def f_Hx_plain(*args):
                   inputs_ = args[:len(inputs)]
                   xs = args[len(inputs):]
                   flat_xs = np.concatenate([np.reshape(x, (-1,)) for x in xs])
                   param_val = self.target.get_param_values(trainable=True)
                   eps = np.cast['float32'](
                       self.base_eps / (np.linalg.norm(param_val) + 1e-8))
                   self.target.set_param_values(
                       param_val + eps * flat_xs, trainable=True)
                   flat_grad_dvplus = self.opt_fun["f_grad"](*inputs_)
                   if self.symmetric:
                       self.target.set_param_values(
                           param_val - eps * flat_xs, trainable=True)
                       flat_grad_dvminus = self.opt_fun["f_grad"](*inputs_)
                       hx = (flat_grad_dvplus - flat_grad_dvminus) / (2 * eps)
                       self.target.set_param_values(param_val, trainable=True)
                   else:
                       self.target.set_param_values(param_val, trainable=True)
                       flat_grad = self.opt_fun["f_grad"](*inputs_)
                       hx = (flat_grad_dvplus - flat_grad) / eps
                   return hx
       
               self.opt_fun = ext.lazydict(
                   f_grad=lambda: ext.compile_function(
                       inputs=inputs,
                       outputs=flat_grad,
                       log_name="f_grad",
                   ),
                   f_Hx_plain=lambda: f_Hx_plain,
               )
       
    1:     def build_eval(self, inputs):
               def eval(x):
                   xs = tuple(self.target.flat_to_params(x, trainable=True))
                   ret = sliced_fun(self.opt_fun["f_Hx_plain"], self._num_slices)(
                       inputs, xs) + self.reg_coeff * x
                   return ret
       
               return eval
       
       
    2: class ConjugateConstraintOptimizer(Serializable):
    1:     """
           Performs constrained optimization via line search. The search direction is computed using a conjugate gradient
           algorithm, which gives x = A^{-1}g, where A is a second order approximation of the constraint and g is the gradient
           of the loss function.
           """
       
    1:     def __init__(
                   self,
                   cg_iters=10,
                   verbose_cg=False,
                   resample_inputs=False,
                   reg_coeff=1e-5,
                   subsample_factor=1.,
                   backtrack_ratio=0.8,
                   max_backtracks=15,
                   accept_violation=False,
                   hvp_approach=None,
                   num_slices=1,
                   linesearch_infeasible_recovery=True):
               """
       
               :param cg_iters: The number of CG iterations used to calculate A^-1 g
               :param reg_coeff: A small value so that A -> A + reg*I
               :param subsample_factor: Subsampling factor to reduce samples when using "conjugate gradient. Since the
               computation time for the descent direction dominates, this can greatly reduce the overall computation time.
               :param accept_violation: whether to accept the descent step if it violates the line search condition after
               exhausting all backtracking budgets
               :return:
               """
    1:         Serializable.quick_init(self, locals())
    1:         self._cg_iters = cg_iters
    1:         self._verbose_cg = verbose_cg
    1:         self._resample_inputs = resample_inputs
    1:         self._reg_coeff = reg_coeff
    1:         self._subsample_factor = subsample_factor
    1:         self._backtrack_ratio = backtrack_ratio
    1:         self._max_backtracks = max_backtracks
    1:         self._num_slices = num_slices
    1:         self._linesearch_infeasible_recovery = linesearch_infeasible_recovery
       
    1:         self._opt_fun = None
    1:         self._target = None
    1:         self._max_constraint_val = None
    1:         self._constraint_name = None
    1:         self._accept_violation = accept_violation
    1:         if hvp_approach is None:
    1:             hvp_approach = PerlmutterHvp(num_slices)
    1:         self._hvp_approach = hvp_approach
       
       
    1:     def update_opt(self, loss, target, quad_leq_constraint, lin_leq_constraint, inputs, 
                           extra_inputs=None, 
                           constraint_name_1="quad_constraint",
                           constraint_name_2="lin_constraint", 
                           using_surrogate=False,
                           true_linear_leq_constraint=None,
                           precompute=False,
                           attempt_feasible_recovery=False,
                           attempt_infeasible_recovery=False,
                           revert_to_last_safe_point=False,
                           *args, **kwargs):
               """
               :param loss: Symbolic expression for the loss function.
               :param target: A parameterized object to optimize over. It should implement methods of the
               :class:`rllab.core.paramerized.Parameterized` class.
               :param lin_leq_constraint: A constraint provided as a tuple (f, epsilon), of the form f(*inputs) <= epsilon. 
                   This constraint will be linearized.
               :param quad_leq_constraint: A constraint provided as a tuple (f, epsilon), of the form f(*inputs) <= epsilon. 
                   This constraint will be quadratified.
               :param inputs: A list of symbolic variables as inputs, which could be subsampled if needed. It is assumed
               that the first dimension of these inputs should correspond to the number of data points
               :param extra_inputs: A list of symbolic variables as extra inputs which should not be subsampled
               :return: No return value.
       
               All right, on the business of this "using_surrogate" and "true_linear_leq_constraint" stuff...
               In rllab, when we optimize a policy, we minimize a "surrogate loss" function (or, if you prefer,
               maximize a surrogate return). The surrogate loss function we optimize is
       
                       mean( lr * advantage ),
       
               where 'lr' is the likelihood ratio of the new policy with respect to the old policy,
       
                       lr(s,a) = pi_new(a|s) / pi_old(a|s).
       
               We choose this surrogate loss function because its gradient is equal to the gradient of the true 
               objective function when pi_new = pi_old. 
       
               However, the real thing we want to optimize is 
       
                       J(pi) = E_{tau ~ pi} [R(tau)].
       
               If we wanted to measure J(pi_old), it would not suffice to calculate the surrogate loss function at pi_old. 
       
               Usually this is not an issue because we don't actually need to compute J(pi_old) at all, because we have no need
               for it. But in our optimization procedure here, we need to calculate a directly analogous property - 
               - the expected safety return - because its value matters for constraint enforcement in our linear approximation.
       
               So, "using_surrogate" and "true_linear_leq_constraint" are here to handle the cases where the "lin_leq_constraint"
               argument submitted by the user is really a SURROGATE leq_constraint, which we can get a good gradient from, 
               but when we need a different symbolic expression to actually evaluate the linear_leq_constraint.
       
               "use_surrogate" is the flag indicating that the lin_leq_constraint argument is in fact a surrogate, 
               and then "true_linear_leq_constraint" is for the actual value. 
       
               :param precompute: Use an 'input' for the linearization constant instead of true_linear_leq_constraint.
                                  If present, overrides surrogate
                                  When using precompute, the last input is the precomputed linearization constant
       
               :param attempt_(in)feasible_recovery: deals with cases where x=0 is infeasible point but problem still feasible
                                                                      (where optimization problem is entirely infeasible)
       
               :param revert_to_last_safe_point: Behavior protocol for situation when optimization problem is entirely infeasible.
                                                 Specifies that we should just reset the parameters to the last point
                                                 that satisfied constraint.
       
               """
       
    1:         self.precompute = precompute
    1:         self.attempt_feasible_recovery = attempt_feasible_recovery
    1:         self.attempt_infeasible_recovery = attempt_infeasible_recovery
    1:         self.revert_to_last_safe_point = revert_to_last_safe_point
       
    1:         inputs = tuple(inputs)
    1:         if extra_inputs is None:
    1:             extra_inputs = tuple()
               else:
                   extra_inputs = tuple(extra_inputs)
       
    1:         constraint_term_1, constraint_value_1 = quad_leq_constraint
    1:         constraint_term_2, constraint_value_2 = lin_leq_constraint
       
    1:         params = target.get_params(trainable=True)
    1:         grads = theano.grad(loss, wrt=params, disconnected_inputs='warn')
    1:         flat_grad = ext.flatten_tensor_variables(grads)
       
    1:         lin_constraint_grads = theano.grad(constraint_term_2, wrt=params, disconnected_inputs='warn')
    1:         flat_lin_constraint_grad = ext.flatten_tensor_variables(lin_constraint_grads)
       
    1:         if using_surrogate and not(precompute):
                   constraint_term_2 = true_linear_leq_constraint
       
    2:         self._hvp_approach.update_opt(f=constraint_term_1, target=target, 
    1:                                       inputs=inputs + extra_inputs,
    1:                                       reg_coeff=self._reg_coeff)
       
    1:         self._target = target
    1:         self._max_quad_constraint_val = constraint_value_1
    1:         self._max_lin_constraint_val = constraint_value_2
    1:         self._constraint_name_1 = constraint_name_1
    1:         self._constraint_name_2 = constraint_name_2
       
    2:         self._opt_fun = ext.lazydict(
    3:             f_loss=lambda: ext.compile_function(
    1:                 inputs=inputs + extra_inputs,
    1:                 outputs=loss,
    1:                 log_name="f_loss",
                   ),
    3:             f_grad=lambda: ext.compile_function(
    1:                 inputs=inputs + extra_inputs,
    1:                 outputs=flat_grad,
    1:                 log_name="f_grad",
                   ),
    1:             f_quad_constraint=lambda: ext.compile_function(
                       inputs=inputs + extra_inputs,
                       outputs=constraint_term_1,
                       log_name="quad_constraint",
                   ),
    3:             f_lin_constraint=lambda: ext.compile_function(
    1:                 inputs=inputs + extra_inputs,
    1:                 outputs=constraint_term_2,
    1:                 log_name="lin_constraint",
                   ),
    3:             f_lin_constraint_grad=lambda: ext.compile_function(
    1:                 inputs=inputs + extra_inputs,
    1:                 outputs=flat_lin_constraint_grad,
    1:                 log_name="lin_constraint_grad",
                   ),
    3:             f_loss_constraint=lambda: ext.compile_function(
    1:                 inputs=inputs + extra_inputs,
    1:                 outputs=[loss, constraint_term_1, constraint_term_2],
    1:                 log_name="f_loss_constraint",
                   ),
               )
       
    1:         self.last_safe_point = None
    1:         self._last_lin_pred_S = 0
    1:         self._last_surr_pred_S = 0
       
    1:     def loss(self, inputs, extra_inputs=None):
    4:         inputs = tuple(inputs)
    4:         if extra_inputs is None:
    4:             extra_inputs = tuple()
    4:         return sliced_fun(self._opt_fun["f_loss"], self._num_slices)(inputs, extra_inputs)
       
    1:     def constraint_val(self, inputs, extra_inputs=None):
               inputs = tuple(inputs)
               if extra_inputs is None:
                   extra_inputs = tuple()
               return sliced_fun(self._opt_fun["f_constraint"], self._num_slices)(inputs, extra_inputs)
       
    1:     def optimize(self, 
                        inputs, 
                        extra_inputs=None, 
                        subsample_grouped_inputs=None, 
                        precomputed_eval=None, 
                        precomputed_threshold=None,
                        diff_threshold=False,
                        inputs2=None,
                        extra_inputs2=None,
                       ):
       
               """
               precomputed_eval         :  The value of the safety constraint at theta = theta_old. 
                                           Provide this when the lin_constraint function is a surrogate, and evaluating it at 
                                           theta_old will not give you the correct value.
       
               precomputed_threshold &
               diff_threshold           :  These relate to the linesearch that is used to ensure constraint satisfaction.
                                           If the lin_constraint function is indeed the safety constraint function, then it 
                                           suffices to check that lin_constraint < max_lin_constraint_val to ensure satisfaction.
                                           But if the lin_constraint function is a surrogate - ie, it only has the same
                                           /gradient/ as the safety constraint - then the threshold we check it against has to
                                           be adjusted. You can provide a fixed adjusted threshold via "precomputed_threshold."
                                           When "diff_threshold" == True, instead of checking
                                               lin_constraint < threshold,
                                           it will check
                                               lin_constraint - old_lin_constraint < threshold.
               """
       
    2:         inputs = tuple(inputs)
    2:         if extra_inputs is None:
    2:             extra_inputs = tuple()
       
               # inputs2 and extra_inputs2 are for calculation of the linearized constraint.
               # This functionality - of having separate inputs for that constraint - is 
               # intended to allow a "learning without forgetting" setup.
    2:         if inputs2 is None:
    2:             inputs2 = inputs
    2:         if extra_inputs2 is None:
    2:             extra_inputs2 = tuple()
       
    2:         def subsampled_inputs(inputs,subsample_grouped_inputs):
    2:             if self._subsample_factor < 1:
    2:                 if subsample_grouped_inputs is None:
    2:                     subsample_grouped_inputs = [inputs]
    2:                 subsample_inputs = tuple()
    4:                 for inputs_grouped in subsample_grouped_inputs:
    2:                     n_samples = len(inputs_grouped[0])
    4:                     inds = np.random.choice(
    2:                         n_samples, int(n_samples * self._subsample_factor), replace=False)
   18:                     subsample_inputs += tuple([x[inds] for x in inputs_grouped])
                   else:
                       subsample_inputs = inputs
    2:             return subsample_inputs
       
    2:         subsample_inputs = subsampled_inputs(inputs,subsample_grouped_inputs)
    2:         if self._resample_inputs:
                   subsample_inputs2 = subsampled_inputs(inputs,subsample_grouped_inputs)
       
    2:         logger.log("computing loss before")
    4:         loss_before = sliced_fun(self._opt_fun["f_loss"], self._num_slices)(
    2:             inputs, extra_inputs)
    2:         logger.log("performing update")
    2:         logger.log("computing descent direction")
       
    4:         flat_g = sliced_fun(self._opt_fun["f_grad"], self._num_slices)(
    2:             inputs, extra_inputs)
    4:         flat_b = sliced_fun(self._opt_fun["f_lin_constraint_grad"], self._num_slices)(
    2:             inputs2, extra_inputs2)
       
    2:         Hx = self._hvp_approach.build_eval(subsample_inputs + extra_inputs)
    2:         v = krylov.cg(Hx, flat_g, cg_iters=self._cg_iters, verbose=self._verbose_cg)
       
    2:         approx_g = Hx(v)
    2:         q = v.dot(approx_g) # approx = g^T H^{-1} g
    2:         delta = 2 * self._max_quad_constraint_val
        
    2:         eps = 1e-8
       
    2:         residual = np.sqrt((approx_g - flat_g).dot(approx_g - flat_g))
    2:         rescale  = q / (v.dot(v))
    2:         logger.record_tabular("OptimDiagnostic_Residual",residual)
    2:         logger.record_tabular("OptimDiagnostic_Rescale", rescale)
       
    2:         if self.precompute:
    2:             S = precomputed_eval
    2:             assert(np.ndim(S)==0) # please be a scalar
               else:
                   S = sliced_fun(self._opt_fun["lin_constraint"], self._num_slices)(inputs, extra_inputs) 
       
    2:         c = S - self._max_lin_constraint_val
    2:         if c > 0:
                   logger.log("warning! safety constraint is already violated")
               else:
                   # the current parameters constitute a feasible point: save it as "last good point"
    2:             self.last_safe_point = np.copy(self._target.get_param_values(trainable=True))
       
               # can't stop won't stop (unless something in the conditional checks / calculations that follow
               # require premature stopping of optimization process)
    2:         stop_flag = False
       
    2:         if flat_b.dot(flat_b) <= eps :
                   # if safety gradient is zero, linear constraint is not present;
                   # ignore its implementation.
                   lam = np.sqrt(q / delta)
                   nu = 0
                   w = 0
                   r,s,A,B = 0,0,0,0
                   optim_case = 4
               else:
    2:             if self._resample_inputs:
                       Hx = self._hvp_approach.build_eval(subsample_inputs2 + extra_inputs)
       
    2:             norm_b = np.sqrt(flat_b.dot(flat_b))
    2:             unit_b = flat_b / norm_b
    2:             w = norm_b * krylov.cg(Hx, unit_b, cg_iters=self._cg_iters, verbose=self._verbose_cg)
       
    2:             r = w.dot(approx_g) # approx = b^T H^{-1} g
    2:             s = w.dot(Hx(w))    # approx = b^T H^{-1} b
       
                   # figure out lambda coeff (lagrange multiplier for trust region)
                   # and nu coeff (lagrange multiplier for linear constraint)
    2:             A = q - r**2 / s                # this should always be positive by Cauchy-Schwarz
    2:             B = delta - c**2 / s            # this one says whether or not the closest point on the plane is feasible
       
                   # if (B < 0), that means the trust region plane doesn't intersect the safety boundary
       
    2:             if c <0 and B < 0:
                       # point in trust region is feasible and safety boundary doesn't intersect
                       # ==> entire trust region is feasible
    2:                 optim_case = 3
                   elif c < 0 and B > 0:
                       # x = 0 is feasible and safety boundary intersects
                       # ==> most of trust region is feasible
                       optim_case = 2
                   elif c > 0 and B > 0:
                       # x = 0 is infeasible (bad! unsafe!) and safety boundary intersects
                       # ==> part of trust region is feasible
                       # ==> this is 'recovery mode'
                       optim_case = 1
                       if self.attempt_feasible_recovery:
                           logger.log("alert! conjugate constraint optimizer is attempting feasible recovery")
                       else:
                           logger.log("alert! problem is feasible but needs recovery, and we were instructed not to attempt recovery")
                           stop_flag = True
                   else:
                       # x = 0 infeasible (bad! unsafe!) and safety boundary doesn't intersect
                       # ==> whole trust region infeasible
                       # ==> optimization problem infeasible!!!
                       optim_case = 0
                       if self.attempt_infeasible_recovery:
                           logger.log("alert! conjugate constraint optimizer is attempting infeasible recovery")
                       else:
                           logger.log("alert! problem is infeasible, and we were instructed not to attempt recovery")
                           stop_flag = True
       
       
                   # default dual vars, which assume safety constraint inactive
                   # (this corresponds to either optim_case == 3,
                   #  or optim_case == 2 under certain conditions)
    2:             lam = np.sqrt(q / delta)
    2:             nu  = 0
       
    2:             if optim_case == 2 or optim_case == 1:
       
                       # dual function is piecewise continuous
                       # on region (a):
                       #
                       #   L(lam) = -1/2 (A / lam + B * lam) - r * c / s
                       # 
                       # on region (b):
                       #
                       #   L(lam) = -1/2 (q / lam + delta * lam)
                       # 
       
                       lam_mid = r / c
                       L_mid = - 0.5 * (q / lam_mid + lam_mid * delta)
       
                       lam_a = np.sqrt(A / (B + eps))
                       L_a = -np.sqrt(A*B) - r*c / (s + eps)                 
                       # note that for optim_case == 1 or 2, B > 0, so this calculation should never be an issue
       
                       lam_b = np.sqrt(q / delta)
                       L_b = -np.sqrt(q * delta)
       
                       #those lam's are solns to the pieces of piecewise continuous dual function.
                       #the domains of the pieces depend on whether or not c < 0 (x=0 feasible),
                       #and so projection back on to those domains is determined appropriately.
                       if lam_mid > 0:
                           if c < 0:
                               # here, domain of (a) is [0, lam_mid)
                               # and domain of (b) is (lam_mid, infty)
                               if lam_a > lam_mid:
                                   lam_a = lam_mid
                                   L_a   = L_mid
                               if lam_b < lam_mid:
                                   lam_b = lam_mid
                                   L_b   = L_mid
                           else:
                               # here, domain of (a) is (lam_mid, infty)
                               # and domain of (b) is [0, lam_mid)
                               if lam_a < lam_mid:
                                   lam_a = lam_mid
                                   L_a   = L_mid
                               if lam_b > lam_mid:
                                   lam_b = lam_mid
                                   L_b   = L_mid
       
                           if L_a >= L_b:
                               lam = lam_a
                           else:
                               lam = lam_b
       
                       else:
                           if c < 0:
                               lam = lam_b
                           else:
                               lam = lam_a
       
                       nu = max(0, lam * c - r) / (s + eps)
       
    2:         logger.record_tabular("OptimCase", optim_case)  # 4 / 3: trust region totally in safe region; 
                                                               # 2 : trust region partly intersects safe region, and current point is feasible
                                                               # 1 : trust region partly intersects safe region, and current point is infeasible
                                                               # 0 : trust region does not intersect safe region
    2:         logger.record_tabular("LagrangeLamda", lam) # dual variable for trust region
    2:         logger.record_tabular("LagrangeNu", nu)     # dual variable for safety constraint
    2:         logger.record_tabular("OptimDiagnostic_q",q) # approx = g^T H^{-1} g
    2:         logger.record_tabular("OptimDiagnostic_r",r) # approx = b^T H^{-1} g
    2:         logger.record_tabular("OptimDiagnostic_s",s) # approx = b^T H^{-1} b
    2:         logger.record_tabular("OptimDiagnostic_c",c) # if > 0, constraint is violated
    2:         logger.record_tabular("OptimDiagnostic_A",A) 
    2:         logger.record_tabular("OptimDiagnostic_B",B)
    2:         logger.record_tabular("OptimDiagnostic_S",S)
    2:         if nu == 0:
    2:             logger.log("safety constraint is not active!")
       
       
       
               # Predict worst-case next S
    2:         nextS = S + np.sqrt(delta * s)
    2:         logger.record_tabular("OptimDiagnostic_WorstNextS",nextS)
       
       
               # for cases where we will not attempt recovery, we stop here. we didn't stop earlier
               # because first we wanted to record the various critical quantities for understanding the failure mode
               # (such as optim_case, B, c, S). Also, the logger gets angry if you are inconsistent about recording
               # a given quantity from iteration to iteration. That's why we have to record a BacktrackIters here.
    2:         def record_zeros():
                   logger.record_tabular("BacktrackIters", 0)
                   logger.record_tabular("LossRejects", 0)
                   logger.record_tabular("QuadRejects", 0)
                   logger.record_tabular("LinRejects", 0)
       
       
    2:         if optim_case > 0:
    2:             flat_descent_step = (1. / (lam + eps) ) * ( v + nu * w )
               else:
                   # current default behavior for attempting infeasible recovery:
                   # take a step on natural safety gradient
                   flat_descent_step = np.sqrt(delta / (s + eps)) * w
       
    2:         logger.log("descent direction computed")
       
    2:         prev_param = np.copy(self._target.get_param_values(trainable=True))
       
    6:         prev_lin_constraint_val = sliced_fun(
    4:             self._opt_fun["f_lin_constraint"], self._num_slices)(inputs, extra_inputs)
    2:         logger.record_tabular("PrevLinConstVal",prev_lin_constraint_val)
       
    2:         lin_reject_threshold = self._max_lin_constraint_val
    2:         if precomputed_threshold is not None:
    2:             lin_reject_threshold = precomputed_threshold
    2:         if diff_threshold:
    2:             lin_reject_threshold += prev_lin_constraint_val
    2:         logger.record_tabular("LinRejectThreshold",lin_reject_threshold)
       
       
    2:         def check_nan():
                   loss, quad_constraint_val, lin_constraint_val = sliced_fun(
                       self._opt_fun["f_loss_constraint"], self._num_slices)(inputs, extra_inputs)
                   if np.isnan(loss) or np.isnan(quad_constraint_val) or np.isnan(lin_constraint_val):
                       logger.log("Something is NaN. Rejecting the step!")
                       if np.isnan(loss):
                           logger.log("Violated because loss is NaN")
                       if np.isnan(quad_constraint_val):
                           logger.log("Violated because quad_constraint %s is NaN" %
                                      self._constraint_name_1)
                       if np.isnan(lin_constraint_val):
                           logger.log("Violated because lin_constraint %s is NaN" %
                                      self._constraint_name_2)
                       self._target.set_param_values(prev_param, trainable=True)
       
    2:         def line_search(check_loss=True, check_quad=True, check_lin=True):
    2:             loss_rejects = 0
    2:             quad_rejects = 0
    2:             lin_rejects  = 0
    2:             n_iter = 0
    4:             for n_iter, ratio in enumerate(self._backtrack_ratio ** np.arange(self._max_backtracks)):
    4:                 cur_step = ratio * flat_descent_step
    4:                 cur_param = prev_param - cur_step
    4:                 self._target.set_param_values(cur_param, trainable=True)
   12:                 loss, quad_constraint_val, lin_constraint_val = sliced_fun(
    8:                     self._opt_fun["f_loss_constraint"], self._num_slices)(inputs, extra_inputs)
    4:                 loss_flag = loss < loss_before
    4:                 quad_flag = quad_constraint_val <= self._max_quad_constraint_val
    4:                 lin_flag  = lin_constraint_val  <= lin_reject_threshold
    4:                 if check_loss and not(loss_flag):
                           logger.log("At backtrack itr %i, loss failed to improve." % n_iter)
                           loss_rejects += 1
    4:                 if check_quad and not(quad_flag):
    2:                     logger.log("At backtrack itr %i, quad constraint violated." % n_iter)
    2:                     logger.log("Quad constraint violation was %.3f %%." % (100*(quad_constraint_val / self._max_quad_constraint_val) - 100))
    2:                     quad_rejects += 1
    4:                 if check_lin and not(lin_flag):
                           logger.log("At backtrack itr %i, expression for lin constraint failed to improve." % n_iter)
                           logger.log("Lin constraint violation was %.3f %%." % (100*(lin_constraint_val / lin_reject_threshold) - 100))
                           lin_rejects += 1
       
    4:                 if (loss_flag or not(check_loss)) and (quad_flag or not(check_quad)) and (lin_flag or not(check_lin)):
    2:                     logger.log("Accepted step at backtrack itr %i." % n_iter)
    2:                     break
       
    2:             logger.record_tabular("BacktrackIters", n_iter)
    2:             logger.record_tabular("LossRejects", loss_rejects)
    2:             logger.record_tabular("QuadRejects", quad_rejects)
    2:             logger.record_tabular("LinRejects", lin_rejects)
    2:             return loss, quad_constraint_val, lin_constraint_val, n_iter
       
       
    2:         def wrap_up():
    2:             if optim_case < 4:
    6:                 lin_constraint_val = sliced_fun(
    4:                     self._opt_fun["f_lin_constraint"], self._num_slices)(inputs, extra_inputs)
    2:                 lin_constraint_delta = lin_constraint_val - prev_lin_constraint_val
    2:                 logger.record_tabular("LinConstraintDelta",lin_constraint_delta)
       
    2:                 cur_param = self._target.get_param_values()
                       
    2:                 next_linear_S = S + flat_b.dot(cur_param - prev_param)
    2:                 next_surrogate_S = S + lin_constraint_delta
       
    2:                 lin_surrogate_acc = 100.*(next_linear_S - next_surrogate_S) / next_surrogate_S
       
    2:                 logger.record_tabular("PredictedLinearS",next_linear_S)
    2:                 logger.record_tabular("PredictedSurrogateS",next_surrogate_S)
    2:                 logger.record_tabular("LinearSurrogateErr",lin_surrogate_acc)
       
       
    2:                 lin_pred_err = (self._last_lin_pred_S - S) #/ (S + eps)
    2:                 surr_pred_err = (self._last_surr_pred_S - S) #/ (S + eps)
    2:                 logger.record_tabular("PredictionErrorLinearS", lin_pred_err)
    2:                 logger.record_tabular("PredictionErrorSurrogateS", surr_pred_err)
    2:                 self._last_lin_pred_S = next_linear_S
    2:                 self._last_surr_pred_S = next_surrogate_S
       
                   else:
                       logger.record_tabular("LinConstraintDelta",0)
                       logger.record_tabular("PredictedLinearS",0)
                       logger.record_tabular("PredictedSurrogateS",0)
                       logger.record_tabular("LinearSurrogateErr",0)
       
                       lin_pred_err = (self._last_lin_pred_S - 0) #/ (S + eps)
                       surr_pred_err = (self._last_surr_pred_S - 0) #/ (S + eps)
                       logger.record_tabular("PredictionErrorLinearS", lin_pred_err)
                       logger.record_tabular("PredictionErrorSurrogateS", surr_pred_err)
                       self._last_lin_pred_S = 0
                       self._last_surr_pred_S = 0
       
    2:         if stop_flag==True:
                   record_zeros()
                   wrap_up()
                   return
       
    2:         if optim_case == 1 and not(self.revert_to_last_safe_point):
                   if self._linesearch_infeasible_recovery:
                       logger.log("feasible recovery mode: constrained natural gradient step. performing linesearch on constraints.")
                       line_search(False,True,True)
                   else:
                       self._target.set_param_values(prev_param - flat_descent_step, trainable=True)
                       logger.log("feasible recovery mode: constrained natural gradient step. no linesearch performed.")
                   check_nan()
                   record_zeros()
                   wrap_up()
                   return
    2:         elif optim_case == 0 and not(self.revert_to_last_safe_point):
                   if self._linesearch_infeasible_recovery:
                       logger.log("infeasible recovery mode: natural safety step. performing linesearch on constraints.")
                       line_search(False,True,True)
                   else:
                       self._target.set_param_values(prev_param - flat_descent_step, trainable=True)
                       logger.log("infeasible recovery mode: natural safety gradient step. no linesearch performed.")
                   check_nan()
                   record_zeros()
                   wrap_up()
                   return
    2:         elif (optim_case == 0 or optim_case == 1) and self.revert_to_last_safe_point:
                   if self.last_safe_point:
                       self._target.set_param_values(self.last_safe_point, trainable=True)
                       logger.log("infeasible recovery mode: reverted to last safe point!")
                   else:
                       logger.log("alert! infeasible recovery mode failed: no last safe point to revert to.")
                   record_zeros()
                   wrap_up()
                   return
       
       
    2:         loss, quad_constraint_val, lin_constraint_val, n_iter = line_search()
       
    6:         if (np.isnan(loss) or np.isnan(quad_constraint_val) or np.isnan(lin_constraint_val) or loss >= loss_before 
    2:             or quad_constraint_val >= self._max_quad_constraint_val
    2:             or lin_constraint_val > lin_reject_threshold) and not self._accept_violation:
                   logger.log("Line search condition violated. Rejecting the step!")
                   if np.isnan(loss):
                       logger.log("Violated because loss is NaN")
                   if np.isnan(quad_constraint_val):
                       logger.log("Violated because quad_constraint %s is NaN" %
                                  self._constraint_name_1)
                   if np.isnan(lin_constraint_val):
                       logger.log("Violated because lin_constraint %s is NaN" %
                                  self._constraint_name_2)
                   if loss >= loss_before:
                       logger.log("Violated because loss not improving")
                   if quad_constraint_val >= self._max_quad_constraint_val:
                       logger.log(
                           "Violated because constraint %s is violated" % self._constraint_name_1)
                   if lin_constraint_val > lin_reject_threshold:
                       logger.log(
                           "Violated because constraint %s exceeded threshold" % self._constraint_name_2)
                   self._target.set_param_values(prev_param, trainable=True)
    2:         logger.log("backtrack iters: %d" % n_iter)
    2:         logger.log("computing loss after")
    2:         logger.log("optimization finished")
    2:         wrap_up()
               
